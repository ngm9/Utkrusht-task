{
    "organization": {
        "organization_id": "bfbd7da3-a43b-47dc-b828-146733b5c81e",
        "organization_name": "Utkrusht",
        "organization_background": "Utkrusht is a proof-of-skills marketplace that helps agile teams find talent with strong fundamental concepts with within days. We help aspiring professionals improve their profile with continuous improvement in their skills, documenting their journey and helping them fulfill their potential. We primarily build, conduct, proctor and disseminate proof-of-skill assessments in Technical domains like AI, ML, Fullstack development, High scale distributed systems, DevOps etc but do help non-tech roles like Sales, HR, Marketing etc" 
    },
      "role_context": "A software engineer with 1–2 years of experience working with large language models and basic Retrieval-Augmented Generation (RAG) concepts is expected to understand how external documents can be searched and used to improve LLM responses. They should be able to work with simple embedding models, perform basic text chunking, store vectors in a lightweight vector DB or an in-memory index, and build small retrieval pipelines under guidance. The engineer should be comfortable integrating retrieved text into prompts, performing simple relevance checks, and following established patterns for reducing hallucinations. They are not expected to design complex retrieval architectures but should implement and troubleshoot basic RAG features with supervision.",
    
      "questions_prompt": "Please ensure the questions you ask assess the candidate’s basic understanding of retrieval workflows and how LLMs use external context:\n\n- **Fundamental RAG Concepts**: The candidate should know what RAG is, why it is used, and how retrieval helps keep LLM responses grounded in real data.\n\n- **Embeddings & Chunking Basics**: They should understand the purpose of text embeddings, how simple chunking works, and why chunk size affects retrieval quality.\n\n- **Simple Vector Search**: The candidate should be familiar with basic similarity search (e.g., cosine similarity, top-k lookup) using an in-memory store or simple vector database.\n\n- **Context Injection Into Prompts**: They should know how retrieved text is inserted into the final prompt and how this improves the accuracy of model responses.\n\n- **Basic Debugging & Quality Awareness**: They should demonstrate awareness of common beginner issues—irrelevant chunks, missing embeddings, duplicated data, or small mistakes in chunking or retrieval.\n\nThe goal is to evaluate whether the candidate can build and reason about simple RAG pipelines, prepare documents for retrieval, and integrate retrieved context into LLM prompts with guidance.",    
      "yoe": "1-2"

}
