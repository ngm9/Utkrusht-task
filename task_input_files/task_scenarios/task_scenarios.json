{
  "JAVA (BASIC), KAFKA (BASIC)": [
    "A simple order processing service written in Java fails to publish messages to the 'order-events' topic. The KafkaProducer configuration has incorrect bootstrap.servers format and missing key/value serializers. The Order POJO class lacks proper encapsulation with private fields and getter methods, causing serialization errors.",
    "User activity tracking service produces inconsistent message ordering across partitions. The Java producer uses incorrect partitioning strategy with null keys, and the consumer application doesn't understand single-partition ordering guarantees. The code lacks proper understanding of key-based hashing for maintaining order.",
    "Basic log aggregation service fails during high throughput periods with OutOfMemoryError. The Java consumer application has improper ArrayList usage for batch processing large messages, incorrect heap sizing awareness, and missing proper resource cleanup in finally blocks causing memory leaks.",
    "Product catalog sync service creates duplicate database entries during consumer group rebalancing. The Java application lacks understanding of exactly-once delivery semantics and doesn't implement proper offset management with manual commits. The service uses HashMap incorrectly for deduplication logic.",
    "E-commerce notification service loses messages during broker leader election events. The Java producer lacks proper callback handling for async sends and has incorrect acks configuration. The application doesn't implement idempotent producer settings to prevent message duplication after retries.",
    "Simple user registration event processor shows growing consumer lag in JMX metrics dashboard. The Java application has incorrect auto.offset.reset and enable.auto.commit settings, and the consumer group rebalancing is stuck due to improper session.timeout.ms and max.poll.records configuration."
  ],
  "Python - FastAPI (BASIC), PostgreSQL (BASIC)": [
    "A dashboard endpoint GET /api/dashboard/stats is making 4 separate PostgreSQL queries sequentially to count users, posts, comments, and active sessions. Each query runs one after another in the FastAPI route handler using synchronous psycopg2 calls with a new connection created for every request, and none of the count operations use indexes on the status or created_at columns being filtered. The queries also use SELECT * with COUNT(*) instead of COUNT(id), there's no caching mechanism, and the dashboard also has a related endpoint GET /api/dashboard/recent-activity that fetches the 50 most recent user activities using OFFSET-based pagination which becomes extremely slow as users paginate deeper (OFFSET 1000 takes 5+ seconds). Additionally, the PostgreSQL tables are missing foreign key constraints between users and their posts/comments, causing data integrity issues, and the tables have never been analyzed, resulting in poor query planner statistics. The total response time for the stats endpoint is 3-4 seconds, and under load (20+ concurrent requests), the application runs out of database connections. Optimize both layers comprehensively by: (1) PostgreSQL optimization - create single-field B-tree indexes on status and created_at columns across all four tables, add composite indexes on (status, created_at) for tables that filter on both columns, add foreign key constraints with proper indexes on user_id columns in posts, comments, and sessions tables to ensure referential integrity, rewrite the four separate COUNT queries into a single efficient query using CTEs (WITH clause) or subqueries in a SELECT statement, ensure the query uses COUNT(id) or COUNT(1) instead of COUNT(*) for better performance, create a composite index on (created_at DESC, id) for the activities table to support efficient pagination, run VACUUM ANALYZE on all tables to update statistics for the query planner, and use EXPLAIN ANALYZE to verify all indexes are being used and document the query plan improvements showing index scans instead of sequential scans. (2) FastAPI optimization - convert both the synchronous route handlers (/stats and /recent-activity) to async/await pattern with asyncpg driver, implement a global connection pool with proper configuration (min_size=10, max_size=20, timeout=30s, command_timeout=10s) that's initialized at application startup and shared across all endpoints, refactor the database connection logic into a reusable dependency injection pattern using FastAPI's Depends() for both endpoints, add comprehensive error handling with try-except blocks that catch asyncpg-specific exceptions (ConnectionError, QueryCanceled, etc.) and return appropriate HTTP status codes (503 for connection issues, 408 for timeouts), implement request-level caching for the /stats endpoint using a simple dictionary with TTL (5-minute cache with timestamp checking) to avoid repeated queries, refactor the /recent-activity endpoint to use cursor-based pagination instead of OFFSET by accepting a last_seen_id query parameter and using WHERE id < last_seen_id ORDER BY created_at DESC, id DESC LIMIT 50 pattern, add structured logging using Python's logging module to track query execution times, cache hit/miss rates, and slow query warnings (>1 second), create comprehensive Pydantic models for request validation (optional date range filters for stats, optional last_seen_id for pagination) and response serialization (typed stats object, activity list with proper field types), add input validation to ensure date ranges are valid and last_seen_id is a positive integer, implement a simple response compression middleware or ensure Pydantic models exclude None values to reduce payload size, and add health check logging for database connectivity. "
  ],
  "NodeJs (BASIC), PostgreSQL (BASIC)": [
    "Your Node.js booking system has an appointment creation endpoint that allows double-booking the same time slot for a service provider. The Express route uses the pg library with callback-based code to INSERT appointments, but there's no constraint preventing overlapping bookings for the same provider_id and time_slot. Fix these issues by: adding a composite UNIQUE constraint on (provider_id, time_slot) columns in PostgreSQL, refactoring the callback-based code to async/await with try-catch blocks, and returning appropriate HTTP status codes (409 for conflict by catching PostgreSQL error code 23505, 500 for server errors). Test by attempting to book the same slot twice."
  ],
  "ReactJs (BEGINNER)": [
    "Controlled Form & Validation Fix:Current Implementation: A signup form exists but inputs are uncontrolled, validation is missing, and submission always succeeds even with empty fields. Error handling is not implemented.Required Changes: Convert inputs to controlled components using useState. Add basic validation (required fields, email format, password length). Display inline error messages and prevent submission if invalid.Final Implementation Approach: Maintain form state and error state in a single parent component. Create typed interfaces for form data and errors. Handle submission via a function that validates before updating UI state. Use conditional rendering to show success view after valid submission."
  ],
  "React Frameworks (BASIC)": [
    "You've inherited a user profile component that displays user information, but the component is not updating when new user data is passed as props. The previous developer used class components with incorrect lifecycle methods. Debug and fix the component to properly reflect prop changes, then refactor it to a functional component using appropriate hooks.",
    "An existing todo list application has a memory leak issue where event listeners are not being cleaned up properly, causing performance degradation. The app also has a bug where completed todos reappear after page refresh. Identify and fix the cleanup issues, implement proper useEffect cleanup, and add localStorage persistence for the todo state and also add the dynamic rendering of todos.",
    "Build a tabs component that displays different content sections (Overview, Specifications, Reviews) when users click on different tab buttons. Only one tab's content should be visible at a time. Use state management to track the active tab and apply conditional rendering for content display.",
    "An accordion component for FAQ section is implemented but has accessibility issues: it's not keyboard navigable, screen readers can't understand the expand/collapse functionality, and there are no proper ARIA attributes. Enhance the component to meet basic accessibility standards while maintaining its visual design and functionality.",
    "A notification system component shows success/error messages but has timing issues where notifications don't auto-dismiss, multiple notifications stack incorrectly, and there's no way to manually dismiss them. Implement proper notification queue management with auto-dismiss timers and manual close functionality while ensuring notifications are accessible to screen readers."
  ],
  "PostgreSQL (BASIC)": [
    "A financial services company needs to migrate their legacy database to PostgreSQL while ensuring zero data loss and minimal downtime. Set up a PostgreSQL 16 instance, configure shared_preload_libraries for pg_stat_statements extension, and tune the database for OLTP workload (frequent small transactions). The schema includes: accounts (2M rows), transactions (50M rows), customers (500K rows), and audit_logs (100M rows). Implement proper indexing strategy: B-tree indexes on frequently queried columns, composite indexes for common query patterns, and partial indexes for active accounts. Create a stored procedure using PL/pgSQL for processing transactions that includes ACID compliance verification, uses savepoints for complex multi-step operations, and handles concurrency using advisory locks. Configure pg_dump/pg_restore strategy with custom format for parallel restore capability. Implement point-in-time recovery (PITR) using pg_basebackup and WAL archiving. Set up row-level security policies for multi-tenant data isolation. Create multiple database roles with GRANT/REVOKE permissions following least-privilege principle - separate roles for read-only analytics, application users, and administrators. Monitor bloat using pg_stat_user_tables and schedule appropriate VACUUM ANALYZE jobs. Use window functions (ROW_NUMBER, RANK, SUM OVER PARTITION) to generate a transaction summary report showing running balances. Optimize a query showing sequential scans to use index scans instead."
  ],
  "PostgreSQL(BEGINNER)": [
    "A small e-commerce startup needs a product catalog database. You are tasked with setting up a PostgreSQL instance on your local machine and creating a basic schema. Install PostgreSQL, initialize the database cluster, create a database named 'product_catalog', and design three tables: 'categories' (id, name, description), 'products' (id, category_id, name, price, stock_quantity, created_at), and 'suppliers' (id, name, contact_email). Establish appropriate primary keys and a foreign key relationship between products and categories. Insert sample data for 5 categories, 15 products, and 3 suppliers. Write queries to: ( retrieve all products with their category names, ( find products with stock less than 10, ( calculate the average price per category. Create a logical backup of the entire database and verify the restore process works. Document your connection string and the commands used.",
    "A community library is transitioning from paper records to a digital system. Set up a PostgreSQL database named 'library_system' with three tables: 'members' (member_id, first_name, last_name, email, join_date), 'books' (book_id, title, author, isbn, available_copies), and 'loans' (loan_id, member_id, book_id, loan_date, due_date, return_date). After creating the schema with appropriate constraints, populate it with test data: 20 members, 30 books, and 25 loan records (some returned, some still active). Write SQL queries to: ( list all currently active loans with member and book details, ( find members who have never borrowed a book, ( identify the top 5 most borrowed books. Create a single-column index on the 'isbn' field. Generate a pg_dump backup of just the 'books' table and restore it to a new table called 'books_backup'. Demonstrate transaction management by inserting a new loan within a transaction and rolling it back.",
    "A fitness center wants to track member attendance and class schedules. Install PostgreSQL and create a database called 'fitness_tracker'. Design tables for 'members' (id, name, membership_type, email, phone), 'classes' (id, class_name, instructor, schedule_time, max_capacity), and 'attendance' (id, member_id, class_id, attendance_date). Implement NOT NULL, UNIQUE, and FOREIGN KEY constraints appropriately. Insert realistic data: 25 members, 10 different classes, and 50 attendance records across different dates. Query the database to: ( find which classes are most popular (highest attendance), ( identify members who attended more than 5 classes this month, ( calculate total attendance per instructor using GROUP BY and aggregates. Use psql to display table structures with \\dt and \\d commands. Create and test a connection from a simple Python script using psycopg2, executing a parameterized query to find a member by email. Document all connection parameters and export the schema only (no data) using pg_dump.",
    "A school cafeteria needs to manage meal planning and student meal selections. Set up PostgreSQL and create a 'cafeteria_system' database containing: 'students' (student_id, name, grade, dietary_restrictions), 'meals' (meal_id, meal_name, meal_type, available_date, price), and 'orders' (order_id, student_id, meal_id, order_date, quantity). After defining the schema with proper primary and foreign keys, populate with sample data: 40 students, 20 meals (breakfast, lunch, dinner options), and 60 orders. Write queries to: ( calculate daily revenue by meal_type, ( list students with dietary restrictions and their meal choices to check compatibility, ( find the most popular meal per grade using window functions (ROW_NUMBER). Create a backup strategy using pg_dump for the entire database. Demonstrate your understanding of transactions by simulating a multi-step order process: begin a transaction, insert a new order, update meal availability, and commit. Then show a rollback scenario. Use both psql and a GUI tool (pgAdmin or DBeaver) to verify your results.",
    "A veterinary clinic requires a patient management system. Install and configure PostgreSQL, then create a 'vet_clinic' database with tables: 'pet_owners' (owner_id, name, phone, email, address), 'pets' (pet_id, owner_id, pet_name, species, breed, birth_date), and 'appointments' (appointment_id, pet_id, appointment_date, reason, diagnosis, treatment_cost). Establish all necessary constraints including a FOREIGN KEY from pets to pet_owners and appointments to pets. Load test data: 15 owners, 25 pets (multiple pets per owner allowed), and 35 appointments. Query to: ( generate a report of all appointments for a specific date with owner and pet information using INNER JOINs, ( calculate total revenue per month, ( identify pets that haven't had appointments in the last 6 months,  find the average treatment cost per species. Create indexes on frequently queried columns (appointment_date, owner phone). Set up a new database role with LIMITED privileges (no superuser) that can only SELECT and INSERT into the appointments table. Perform a complete database backup and document the restore procedure. Test your backup by dropping the database and restoring it successfully."
  ],
  "SQL(BEGINNER)": [
    "You are working for an e-commerce company that maintains a 'customers' table with columns: customer_id (INT, PRIMARY KEY), first_name (VARCHAR), last_name (VARCHAR), email (VARCHAR), registration_date (DATE), and country (VARCHAR). Your manager asks you to retrieve a list of all customers who registered in the year 2024, sorted by their registration date in descending order, showing only their full name and email. Write the SQL query to accomplish this task and explain what each part of your query does.",
    "A small retail store has a 'products' table containing: product_id (INT), product_name (VARCHAR), category (VARCHAR), price (DECIMAL), and stock_quantity (INT). The store manager needs to see all products in the 'Electronics' category that have a price less than $500. Display only the product name, price, and stock quantity, limiting the results to the first 10 products. Write the query and identify which data types are being used for price and stock quantity.",
    "You work for a library system with a 'books' table that has: book_id (INT), title (VARCHAR), author (VARCHAR), publication_year (INT), and available_copies (INT). A patron asks you to find all books published between 2015 and 2023 where at least 1 copy is available. Sort the results by publication year in ascending order. After writing the query, explain why using WHERE clause is important instead of retrieving all data first.",
    "Your company has an 'employees' table with columns: employee_id (INT, PRIMARY KEY), employee_name (VARCHAR), department (VARCHAR), hire_date (DATE), and salary (DECIMAL). You need to insert a new employee record: ID=105, Name='John Smith', Department='Sales', Hire Date='2024-10-01', Salary=45000. Write the INSERT statement and then write a SELECT query to verify the record was added correctly. Explain what would happen if you tried to insert another employee with the same employee_id.",
    "A hospital database contains a 'patients' table with: patient_id (INT), patient_name (VARCHAR), date_of_birth (DATE), blood_group (VARCHAR), and contact_number (VARCHAR). You discover that patient with ID 2301 has changed their contact number to '555-9876'. Write an UPDATE statement to modify this record. Then explain why it's crucial to include a WHERE clause in UPDATE statements and what could go wrong if you forget it. Also write a SELECT statement to confirm the update was successful."
  ],
  "Java(BEGINNER)": [
    "Create a simple console-based Student Management System that allows users to input student details (name, roll number, marks in 3 subjects) and calculate the average marks. The program should display whether the student passed (average >= 40) or failed. Use basic classes, objects, and control statements to implement this functionality.",
    "Develop a basic Calculator application that reads two numbers and an operator (+, -, *, /) from the user and displays the result. Implement proper if-else conditions to handle different operators and display an error message for invalid operators. The program should continue running until the user chooses to exit.",
    "Build a simple Bank Account program where a user can create an account with an initial balance, deposit money, withdraw money, and check the current balance. Use a class with basic methods and ensure withdrawal doesn't allow negative balance. Display appropriate messages for each operation using print statements.",
    "Create a Temperature Converter application that converts temperatures between Celsius and Fahrenheit. The program should ask the user to choose conversion type (1 for C to F, 2 for F to C), input the temperature value, perform the conversion using arithmetic operations, and display the result with appropriate labels.",
    "Develop a simple Library Book Tracker where users can add book details (title, author, ISBN) to an array, display all books, and search for a book by title. Use loops to iterate through the array, basic string comparison for search functionality, and display results in a formatted manner on the console."
  ],
  "Java (BASIC)": [
    "Current Implementation: A basic `Library` feature exists with classes `Book` and `Member`, but fields are public, borrowing rules are scattered across classes, and returning a non-borrowed book causes inconsistent state. Identify Required Changes: Apply encapsulation (private fields + getters/setters), centralize borrowing/returning logic, and introduce a simple custom exception for invalid borrow/return operations with meaningful messages. Describe the Final Implementation Approach: Create coherent domain classes (e.g., `Book`, `Member`, `LibraryService`), enforce rules via methods (not direct field edits), and throw/catch specific exceptions to keep the system consistent even when invalid actions occur."

  ],
  "React Native(BASIC)": [
    "Develop a 'Food Ordering' app with tab navigation (Home, Menu, Cart, Profile) using React Navigation. The Menu screen should fetch restaurant items from a mock API, display them in a SectionList grouped by category (Appetizers, Main Course, Desserts), and allow adding items to cart using Context API for global state. Implement cart badge count on the Cart tab, cart item management (add/remove/update quantity), and calculate total price. Use custom hooks for API calls, implement proper error boundaries, apply React.memo for list items to prevent unnecessary re-renders, and style with responsive Flexbox. Store cart data in AsyncStorage to persist across app restarts.",
    "Create a 'Fitness Tracker' app with drawer navigation containing Dashboard, Workouts, and Settings screens. Implement a workout logger where users can record exercises using Modal for input forms. Use Redux Toolkit for state management to handle workout history, user preferences (stored in AsyncStorage), and daily goals. Integrate react-native-geolocation for tracking outdoor activities (with proper permission handling), display location on workouts, and calculate distance. Implement dark/light theme switching using Context, apply appropriate styling with StyleSheet, and ensure accessibility labels for screen readers. Add Fastlane configuration for automated debug builds and write Jest unit tests for Redux reducers and custom hooks.",
    "Build a 'Real Estate Listings' app with stack and tab navigation. Implement infinite scroll FlatList loading properties from a paginated REST API, with optimized rendering using getItemLayout, removeClippedSubviews, and proper key extraction. Add image carousel for property photos using ScrollView with pagingEnabled, implement heart icon to favorite properties (stored in SecureStore for secure persistence), and add filters (price range, bedrooms) using Modal. Integrate react-native-maps to show property locations with custom markers. Use Zustand for lightweight global state, implement deep linking to open specific property details, write snapshot tests with React Native Testing Library, and set up ESLint/Prettier with pre-commit hooks via Husky.",
    "Develop a 'Social Media Feed' clone with authentication flow. Implement login/signup screens with form validation, use Context API for auth state management, and store JWT tokens in SecureStore. Create a feed screen with FlatList displaying posts fetched from GraphQL API using axios, implement pull-to-refresh and infinite scroll, and add like/comment functionality with optimistic UI updates. Integrate react-native-image-picker for uploading post images, handle permissions properly for both platforms, and compress images before upload. Implement push notifications setup with FCM/APNs (configuration only, can use mock tokens), add Sentry for crash reporting, and create release builds for both Android (signed APK) and iOS. Write integration tests for auth flows and set up CI pipeline with GitHub Actions.",
    "Create a 'Expense Tracker' app with multi-screen navigation (Dashboard with charts, Add Expense, History, Reports). Implement local SQLite database for storing expense records with categories, amounts, and dates. Create custom hooks for database operations (useFetchExpenses, useAddExpense), display data visualization using react-native-chart-kit for spending patterns by category. Add expense categories with color coding, implement date range filters, and export data as CSV. Use useCallback and useMemo for performance optimization in calculations, implement search functionality in history with debouncing, ensure WCAG AA contrast ratios, add i18n support for English and Spanish using react-i18next, and write comprehensive Jest tests including Testing Library render tests. Configure Metro bundler for custom asset management and set up separate dev/staging/production environments using react-native-config."
  ],
  "React Native(BEGINNER)": [
    "Create a 'Personal Task List' app where users can add, view, and delete tasks. Implement a TextInput for task entry, a FlatList to display tasks with proper keys, and Pressable components for delete actions. Style the interface using StyleSheet.create with Flexbox properties (justify-content, align-items). Add platform-specific styling using Platform.select for header colors (blue for iOS, green for Android). Include proper state management using useState hook, and ensure the app handles empty list states gracefully with appropriate messaging.",
    "Develop a 'Weather Check' application that fetches current weather data from OpenWeatherMap API for a hardcoded city. Display temperature, weather condition, and an appropriate weather icon using the Image component. Implement async/await for API calls, handle network errors with try-catch blocks, and show loading state during data fetch. Create a ScrollView layout that works in both portrait orientations. Add a 'Refresh' button that re-fetches data and uses setState to update the UI. Ensure proper error messages are displayed when API calls fail.",
    "Build a 'Profile Viewer' app with two screens using React Navigation. The first screen shows a list of 5 user profiles (name, email, avatar) in a FlatList fetched from JSONPlaceholder API (https://jsonplaceholder.typicode.com/users). When a user taps a profile, navigate to a detail screen passing the user data as route params. The detail screen should display full user information including address and company details. Implement proper back navigation, loading indicators, and handle the case when API is unavailable. Use appropriate core components and Flexbox for responsive layout.",
    "Create a 'Photo Gallery' app that displays images in a grid layout using FlatList with numColumns prop. Fetch image data from Picsum Photos API (https://picsum.photos/v2/list?limit=20). Implement pull-to-refresh functionality, handle loading states with ActivityIndicator, and manage errors appropriately. When an image is tapped, show an Alert with the author's name. Apply proper styling using StyleSheet, ensure images scale correctly using Image resizeMode, and handle different screen densities. Request and handle camera roll permissions using PermissionsAndroid for Android (display permission status in UI but actual implementation can be simulated)."
  ],
  "Python-FastAPI(beginner)": [
    "You need to build a simple weather information API. Create a FastAPI application with a GET endpoint '/weather/{city}' that accepts a city name as a path parameter and returns mock weather data (temperature, humidity, condition) as a JSON response. Use Pydantic models to structure the response data. The application should be runnable with uvicorn and include at least one additional GET endpoint '/health' that returns the API status.",
    "Create a basic task management API with FastAPI. Implement two endpoints: POST '/tasks' to add a new task (accepting title and description in the request body) and GET '/tasks' to retrieve all tasks. Store tasks in a simple Python list (no database required). Use Pydantic models for request validation and response serialization. Include basic error handling for missing fields.",
    "Build a simple user registration endpoint using FastAPI. Create a POST endpoint '/register' that accepts user information (username, email, age) in the request body. Validate that the age is greater than 18 using Pydantic model validation. Return appropriate success or validation error messages. Set up the basic FastAPI application structure with proper imports and include a root endpoint '/' that returns a welcome message.",
    "Develop a basic book catalog API. Create GET endpoint '/books' that returns a list of hardcoded books (each with id, title, author, year), and GET endpoint '/books/{book_id}' that returns a specific book by ID. Use path parameters and implement basic error handling when a book ID is not found. Structure the response using Pydantic models and ensure the application can be launched with uvicorn.",
    "Create a simple calculator API with FastAPI. Implement GET endpoints for basic arithmetic operations: '/add/{num1}/{num2}', '/subtract/{num1}/{num2}', '/multiply/{num1}/{num2}', and '/divide/{num1}/{num2}'. Handle the division by zero case with appropriate error response. Use path parameters to accept numbers and return the result in JSON format with Pydantic response models."
  ],
  "Python-FastAPI(basic)": [
    "Build a RESTful contact management API with full CRUD operations. Implement endpoints for creating, reading, updating, and deleting contacts (name, email, phone, address) stored in an in-memory structure. Use APIRouter to organize endpoints, implement proper HTTP methods (GET, POST, PUT, DELETE), add query parameters for filtering contacts by name, and include environment-based configuration for API settings. Write at least 3 unit tests using pytest and TestClient to verify the main operations work correctly.",
    "Create a blog post API with authentication. Implement JWT-based token authentication with endpoints for user login (/token) and protected endpoints for creating and retrieving blog posts. Use dependency injection for authentication verification, implement proper status codes and error responses, store posts in a Python dictionary with user association, and add CORSMiddleware configuration. Include basic logging for authentication attempts",
    "Develop a product inventory API with async operations. Create endpoints to manage products (id, name, price, stock quantity) with async/await patterns. Implement GET /products with pagination using query parameters (skip, limit), POST /products for adding items, PUT /products/{id} for updates, and a background task that simulates stock verification. Use Pydantic models with field validators to ensure price is positive and stock is non-negative. Include environment variable management for configuration and write integration tests covering main workflows.",
    "Build a file metadata tracking API. Create endpoints to upload file information (POST /files - filename, size, type, upload_date), retrieve all files (GET /files with filtering by file type), and get specific file details (GET /files/{file_id}). Implement custom middleware to log request processing time, use proper HTTP status codes, handle errors gracefully with custom exception handlers, and store data in memory using proper data structures. Configure the application with uvicorn. Write tests to verify validation and error handling.",
    "Create a notification service API with multiple routers. Organize the application into separate routers for users (/users) and notifications (/notifications). Implement user registration/retrieval and notification creation/retrieval with proper relationship between them. Add token-based authentication for protected routes, implement rate limiting logic (track requests per user), use async endpoints where appropriate, and configure structured logging. Include environment-specific settings (development/production) and write comprehensive tests using pytest with dependency overrides for authentication."
  ],
  "NodeJS(BEGINNER)": [
    "You are building a simple file-based task manager CLI application. Create a Node.js script that reads a tasks.json file, displays all tasks with their IDs, allows users to add a new task through command-line arguments (e.g., node app.js add 'Buy groceries'), and saves the updated tasks back to the file. Handle the case when the file doesn't exist initially and include basic error handling for file operations.",
    "A small startup needs a basic HTTP server that serves a static HTML homepage and responds to a /api/time endpoint with the current server time in JSON format. Create this server using Node's built-in http module without Express. The server should handle 404 errors for unknown routes and log each incoming request (method and URL) to the console.",
    "You're tasked with creating a simple environment configuration module for a Node.js application. Build a script that reads environment variables from a .env file using dotenv, exports a config object containing DATABASE_URL, PORT, and NODE_ENV variables, and includes a validation function that checks if all required variables are present. If any are missing, the script should log an error message and exit.",
    "Create a basic event-driven notification system using Node's EventEmitter. Build a simple module that emits events when a user registers, logs in, or makes a purchase. Create listener functions that log different messages for each event type. Demonstrate this by creating a main script that imports your module and triggers these events with sample user data.",
    "You need to build a simple CSV file parser for a data import task. Create a Node.js script that reads a CSV file containing user data (name, email, age), parses each line, validates that emails contain '@' symbol and ages are numbers, filters out invalid entries, and writes the valid entries to a new JSON file. Use callbacks for file operations and include error handling."
  ],
  "Python (BEGINNER)": [
    "Explain the Current Implementation: A script reads a text log file and prints each line, but it doesn’t summarize anything and breaks if the file path is wrong.Identify Required Changes: Count occurrences of a given keyword (case-insensitive), print total matches, and save matching lines to an output file; handle missing file errors cleanly.Describe the Final Implementation Approach: Use functions for reading lines, counting matches, filtering lines, and writing output; wrap file operations in try/except; keep CLI input minimal."
  ],
  "Python (BASIC)": [
    "Current Implementation: A config loader module reads a JSON file and returns a raw dict; it does not validate required keys and does not handle missing file or invalid JSON—exceptions are caught and ignored, returning an empty dict. Required Changes: Validate that required keys (e.g. host, port) exist and have correct types; use try/except/finally to handle FileNotFoundError and json.JSONDecodeError and re-raise or log instead of swallowing; return a simple dataclass or named tuple for type clarity. Final Approach: Structure as a small module with one public load_config(path, required_keys) function and a private validator; add a simple unit test with pytest or unittest that covers missing file and invalid JSON.",
    "Current Implementation: A small script processes a list of orders (each with order_id, amount, status) and prints a summary, but the logic is in one long function that mutates a global list and has no error handling for malformed rows. Required Changes: Refactor into a class (e.g. OrderSummary) with __init__(orders), a method to compute totals by status, and proper encapsulation; parse input with validation and skip or log invalid rows instead of crashing; use list comprehensions or collections.Counter where appropriate. Final Approach: One main class, one small runner script; raise ValueError or use a custom exception for invalid data; add at least one test for the summary logic.",
    "Current Implementation: A CSV report generator reads user data and writes a CSV with hardcoded columns; file I/O is not closed on error and duplicate code exists for escaping fields. Required Changes: Use context managers (with open(...)) for both read and write; extract a helper for escaping/sanitizing CSV fields and reuse it; handle missing or malformed input rows (e.g. missing required column) with try/except and log or skip. Final Approach: One module with a function generate_report(input_path, output_path, columns); use pathlib where appropriate; add a simple test that mocks file I/O or uses a temp file.",
    "Current Implementation: A simple HTTP client function fetches a URL and returns the response text; it does not check status codes, has no timeout, and catches all exceptions returning None. Required Changes: Use requests or urllib with a reasonable timeout; raise or return a clear error for non-2xx status codes; use try/except for network errors and re-raise or wrap in a custom exception instead of returning None; add a simple unit test with mocked response. Final Approach: One function in a module, proper exception handling, and at least one test for success and one for failure."
  ],
  "Python (INTERMEDIATE)": [
    "Explain the Current Implementation: Validation rules are hardcoded inside one function with many if/else blocks, making it difficult to add new rules or reuse them across datasets.Identify Required Changes: Design a rule engine where rules are defined as small, composable units (callables or classes), support severity levels (warning/error), and output a structured validation report that can be serialized to JSON.Describe the Final Implementation Approach: Model rules and results with clear interfaces, keep rule execution deterministic, provide a registry for enabling/disabling rules, and write unit tests for rule composition and reporting."
  ],
  "SQL (BASIC)": [
    "Current: An e-commerce DB already has `customers`, `orders`, and `order_items`, but `order_items` allows invalid quantities and some rows reference non-existent orders/products. Required: Write DDL to add/adjust PRIMARY KEY + FOREIGN KEY constraints and a CHECK constraint to prevent quantity <= 0, plus fix the minimal data issues via safe DML. Final: Deliver a clean migration script (CREATE/ALTER) and a verification SELECT using INNER/LEFT JOIN to confirm referential integrity and detect any remaining orphan rows."
  ],
  "SQL (BEGINNER)": [
    "Explain the Current Implementation: A `products` table has a `discount_percent` column, and some rows have incorrect values (negative, over 100, or NULL) due to manual entry.Identify Required Changes: Update only the affected rows to a safe default value, ensuring you do not accidentally update every row.Describe the Final Implementation Approach: Use an UPDATE with a precise WHERE clause using comparisons and IS NULL checks, and verify the result by selecting the updated rows afterward."
  ],
  "NodeJS(BASIC)": [
    "Build a RESTful API for a simple book inventory system using Express.js. Implement GET /books (list all books), GET /books/:id (get single book), POST /books (add new book), and DELETE /books/:id (remove book). Store data in a JSON file using the fs module. Include input validation middleware to ensure book objects have required fields (title, author, ISBN). Add proper error handling and appropriate HTTP status codes.",
    "Create a file upload service that accepts image files through a POST endpoint. Use Express.js with middleware to handle multipart/form-data, validate that uploaded files are images (check MIME type), limit file size to 5MB, save files to an 'uploads' folder with unique filenames, and return the file path in the response. Implement error handling for invalid file types and size limits.",
    "Develop a custom middleware pipeline for an Express application that includes:  A request logger middleware that logs timestamp, method, and URL;  An authentication middleware that checks for an 'api-key' header;  A rate limiter that blocks more than 5 requests per minute from the same IP. Chain these middlewares and demonstrate with a protected route that returns user data. Store rate limit data in memory using a Map object.",
    "Build a simple web scraper using Node.js that fetches data from a public API (JSONPlaceholder or similar), processes the response, filters items based on specific criteria, transforms the data structure, and saves results to a JSON file. Implement retry logic for failed requests (up to 3 attempts) using setTimeout. Add proper async/await error handling and log progress to console.",
    "Create a basic command-line tool for batch file processing. The tool should accept a folder path as argument, read all .txt files in that folder, count words in each file, generate a summary report showing filename and word count, and save the report as summary.json. Use the path and os modules for cross-platform compatibility. Implement the EventEmitter pattern to emit progress events as files are processed."
  ],
  "ExpressJS(BEGINNER)": [
    "You're developing a blog API prototype. Build a modularized Express application with separate route files for posts and comments. Implement CRUD operations: GET/POST for '/api/posts' and GET/POST/DELETE for '/api/posts/:postId/comments'. Use in-memory arrays to store data. Include custom middleware for request logging (timestamp, method, path) and centralized error handling that distinguishes between 404 (route not found) and 500 (server errors). Test all endpoints using Postman and ensure proper JSON responses with appropriate status codes.",
    "Create a restaurant menu management API. Structure your Express app with middleware chain: request logger → express.json() → routes → 404 handler → error handler. Implement routes for '/menu/items' (GET all, POST new), '/menu/items/:id' (GET one, PUT update, DELETE remove) and '/menu/categories' (GET all). Store data in-memory. Write custom middleware that validates required fields (name, price, category) for POST/PUT requests, sending 400 errors for invalid data. Use route parameters and query strings (?category=appetizers) for filtering. Debug using console.log and VS Code breakpoints.",
    "Build a simple event ticketing system API. Create an Express server with routes for '/events' (GET all, POST create), '/events/:eventId' (GET details), and '/events/:eventId/book' (POST booking with attendee info). Implement middleware that adds a unique requestId to each request and logs it. Handle errors: 404 for non-existent events, 400 for invalid booking data, 500 for server issues. Serve a static booking confirmation page from '/public' when booking succeeds. Ensure middleware execution order is correct and test the complete request-response cycle.",
    "Develop a product inventory API with basic business logic. Set up Express with modular routes for '/products' and '/suppliers'. Implement GET /products (with optional ?inStock=true query filter), POST /products (with stock quantity), GET /products/:id, and PUT /products/:id/restock. Use custom middleware to validate product data (name, price must be positive, category required). Add a middleware that checks if stock quantity falls below 5 and logs a warning. Include proper error handling for invalid IDs and malformed requests. Test using Postman with various edge cases.",
    "Create a simple course enrollment API. Build an Express application with routes: GET/POST '/courses', GET '/courses/:courseId', POST '/courses/:courseId/enroll' (accepts student data), GET '/courses/:courseId/students'. Use in-memory data structures. Implement middleware chain: CORS-like headers → JSON parser → custom request validator (checks for required fields) → routes → 404 handler → error handler. Add logic to prevent duplicate enrollments (same student email) and return appropriate errors (409 conflict). Serve static enrollment confirmation HTML. Debug using console logs and verify middleware order affects request processing."
  ],
  "ExpressJS (BASIC)": [
    "You are building a simple portfolio website API. Create an Express server that serves static files from a 'public' folder and has three GET routes: '/about' returning a JSON object with name and bio, '/projects' returning an array of project objects, and '/contact' returning contact information. The server should run on port 3000 and log 'Server running' to console on startup. Include a catch-all route that returns a 404 message for any undefined routes.",
    "A local bookstore needs a basic inventory API. Build an Express application with GET and POST routes for '/books'. The GET route should return a hardcoded array of 5 book objects (each with id, title, author, price). The POST route should use express.json() middleware to accept a new book object and log it to the console, then respond with a success message. Add basic error handling middleware that catches any errors and returns a 500 status with an error message.",
    "Create a simple weather information service. Set up an Express server with route parameters that accepts GET requests to '/weather/:city'. Extract the city name from req.params and return a JSON response with the city name and mock weather data (temperature, condition). Add a middleware function that logs the timestamp and requested URL for every incoming request before processing. Include appropriate status codes (200 for success, 400 for missing city).",
    "Build a basic student registration form handler. Create an Express app that serves a static HTML form from a 'public' folder and has a POST route at '/register' that accepts student data (name, email, course) using body-parser or express.json() middleware. Log the received data to console and send back a confirmation message. Add middleware to handle requests to undefined routes with a custom 404 page response.",
    "Develop a simple task list API for a todo application. Create GET, POST routes at '/tasks' where GET returns a hardcoded array of 3-4 tasks (id, description, completed status) and POST accepts new task data, logs it, and responds with the received task plus a generated ID. Use express.json() middleware for parsing. Add a GET route '/tasks/:id' that returns a specific task or a 404 message if not found. Add a DELETE route '/tasks/:id' to remove a specific task or return a 404 if not found. Implement a custom middleware that logs the HTTP method and URL for each request, ensuring proper middleware ordering. In the POST route, validate that the description field is a non-empty string and return a 400 error if invalid. Finally, make the server listen on port 3000 and log a message when running.And also Add a PUT route '/tasks/:id' to update or toggle the completed status of a task.)"
  ],
  "Java(BASIC),Redis(BASIC)": [
    "You are building a simple blog application where user session data (username, last login time, session token) needs to be stored temporarily. Currently, the Java application stores sessions in an in-memory HashMap, which loses data on server restart. Your task:  Analyze the provided Java code that manages user sessions using HashMap,  Refactor the solution to use Redis Strings or Hashes to store session data with a 30-minute TTL,  Implement basic Redis connection using Jedis or Lettuce client with proper connection pooling (min 5, max 10 connections),  Add simple error handling using try-catch blocks for Redis connection failures and fallback to database lookup,  Write a JUnit test case to verify that sessions expire correctly after the TTL period. Provide the refactored Java code with Redis integration, explain why you chose String vs Hash data structure, and document the basic configuration settings used.",
    "A small e-commerce website needs to implement a product view counter that tracks how many times each product has been viewed. The current Java implementation uses a database UPDATE query for every view, causing slow page loads (2-3 seconds). Your task:  Review the existing Java servlet/controller code that increments view counts in MySQL,  Implement a Redis-based counter using INCR command to track product views with product ID as the key (e.g., 'product:123:views'),  Create a simple Java scheduled task (using Timer or ScheduledExecutorService) that runs every 5 minutes to batch-sync Redis counters back to the database using SCAN and GET commands,  Configure an appropriate eviction policy (volatile-lru or allkeys-lru) in redis.conf and set maxmemory to 256MB,  Add basic monitoring by printing INFO stats (used_memory, total_commands_processed) to console logs every sync cycle. Deliver the Java code showing Redis integration, explain the trade-offs between Redis and database consistency, and provide simple documentation on how to recover if Redis goes down.",
    "Your team is developing a task management application where users can create, update, and retrieve task lists. Each task has properties: id, title, description, priority (1-, and created_date. Currently, tasks are fetched from PostgreSQL on every request. Your task:  Design a caching strategy using Redis to store task lists per user, choosing between String (serialized JSON) or Hash data structures,  Implement a Java service class with methods: getUserTasks(), createTask(), updateTask() that integrate Redis as a read-through cache with 10-minute TTL,  Use proper OOP principles (Encapsulation) by creating a Task model class with appropriate getters/setters and a RedisService class to handle all Redis operations,  Implement cache invalidation: when a task is created or updated, delete the corresponding cache key using DEL command,  Write basic exception handling to catch Redis connection errors and log them, ensuring the application falls back to database queries. Provide the complete Java code with package structure, explain your data structure choice, and describe the cache hit/miss flow in simple terms.",
    "A gaming leaderboard application needs to rank players by their scores in real-time. The current Java implementation sorts player scores in ArrayList on every request, which becomes slow with 10,000+ players. Your task:  Analyze the provided Java code that maintains player scores (playerId, playerName, score) in an ArrayList and sorts it manually,  Refactor to use Redis Sorted Set (ZADD, ZRANGE, ZREVRANGE) to maintain the leaderboard with player IDs as members and scores as scores,  Implement Java methods: updatePlayerScore(), getTopPlayers(int n), getPlayerRank(String playerId) using a Redis client library,  Add basic pipelining to batch multiple ZADD commands when updating scores for multiple players simultaneously,  Configure RDB persistence (save 900 1 300 10) in redis.conf to ensure leaderboard data survives Redis restarts. Provide the refactored Java code, explain the Big-O complexity improvement from ArrayList sorting to Redis Sorted Set operations, and document the basic backup/restore procedure for the leaderboard data.",
    "A news website implements a rate limiter to prevent users from making more than 10 API requests per minute. The current Java solution uses a ConcurrentHashMap to track request counts, but it doesn't work correctly across multiple application servers. Your task:  Review the existing Java rate limiter code using ConcurrentHashMap with timestamp tracking,  Implement a Redis-based rate limiter using the 'Fixed Window' algorithm: store request counts with keys like 'ratelimit:userId:minute' using INCR and EXPIRE commands,  Create a Java RateLimiterService class with a method checkRateLimit(String userId) that returns true/false, properly handling Redis connection exceptions with try-catch-finally blocks,  Use redis-cli to manually test your implementation: simulate 15 requests from the same user and verify that 5 requests are blocked,  Add basic logging (System.out or SLF4J) to track rate limit hits and document the behavior in comments. Deliver the complete Java service code with Redis integration, explain why Redis is better than ConcurrentHashMap for distributed rate limiting, and provide redis-cli commands used for testing with expected outputs."
  ],
  "Python-FastAPI(basic),Redis (basic)": [
    "You are building a simple blog API that needs to cache blog post data to reduce database queries. Your task:  Create a FastAPI application with basic CRUD endpoints (GET, POST, PUT, DELETE) for blog posts using proper HTTP methods and path parameters,  Implement Redis caching using Redis String data type to store individual blog posts by ID with a 5-minute TTL, checking cache before querying the database,  Use Pydantic models for request/response validation with appropriate field types (title, content, author, created_at),  Add simple error handling for Redis connection failures with try-except blocks and proper HTTP status codes, and  Write basic unit tests using pytest and FastAPI's TestClient to verify cache hit/miss behavior. Configure the application to run with uvicorn, use environment variables for Redis connection settings, include basic logging to track cache operations, and provide a simple Docker setup with redis and fastapi services. Document your code with comments explaining the caching strategy and when cache invalidation occurs.",
    "A small e-commerce startup needs a session management system for their shopping cart. Your task:  Build a FastAPI service with endpoints to create, retrieve, and update shopping cart sessions using query parameters for session_id,  Store cart data in Redis using Hash data type where each cart session is a hash containing item_id, quantity, and price fields,  Implement automatic session expiration by setting appropriate TTL (30 minutes of inactivity) on cart keys,  Add a simple token-based authentication mechanism using environment variables for API keys validated in a custom middleware function, and  Create GET endpoint to retrieve total cart value by reading all items from the Redis hash and calculating the sum. Include CORSMiddleware configuration for frontend access, basic logging for all cart operations, simple pytest tests for adding/removing items, and a README with instructions to run the application locally. Use redis-cli commands in your documentation to show how data is structured in Redis, and explain the trade-offs of using in-memory storage versus a database for cart data.",
    "You need to implement a simple rate limiting system for a public API to prevent abuse. Your task:  Create a FastAPI application with a few public endpoints (e.g., /api/search, /api/data) that need rate limiting protection,  Implement a basic rate limiter using Redis String data type with INCR command to count requests per IP address, allowing 10 requests per minute,  Use Redis EXPIRE command to automatically reset counters after 60 seconds,  Create a custom middleware or dependency that checks the rate limit before processing requests and returns 429 Too Many Requests status when limit exceeded, and  Add an endpoint GET /api/rate-limit-status that shows remaining requests for the current IP. Include proper async/await usage in your endpoints, environment variable configuration for rate limit thresholds, basic integration tests using pytest to simulate multiple requests, simple logging for rate limit violations, and Docker containerization. Provide redis-benchmark commands to test your rate limiter's performance and document how you chose the Redis data structure and commands for this use case.",
    "A job board application needs to track and display trending job categories based on user views. Your task:  Build a FastAPI service with endpoints to record job category views (POST /views) and retrieve top 10 trending categories (GET /trending),  Use Redis Sorted Set data type to maintain a leaderboard of categories, incrementing scores with ZINCRBY when a category is viewed,  Implement a GET endpoint that uses ZREVRANGE to fetch the top categories with their view counts,  Add basic Pydantic models for request validation (category_name, view_timestamp) and response serialization (ranking, category, views), and  Create a background task or simple scheduled function that resets the trending data daily using DEL command. Include proper error handling for invalid category names, basic unit tests with TestClient to verify ranking logic, simple authentication using API key in headers, logging for all view events, and environment-based configuration for Redis connection. Provide a docker-compose.yml file to run both FastAPI and Redis services, document the time complexity of Redis sorted set operations you're using, and explain when you would choose Sorted Sets over other Redis data types for this use case.",
    "You are creating a notification system that stores user preferences and delivers simple alerts. Your task:  Build a FastAPI application with endpoints to manage user notification preferences (enable/disable notifications, set frequency) using POST and GET methods with user_id as path parameter,  Store user preferences in Redis using Hash data type with fields like email_enabled, sms_enabled, frequency using HSET and HGETALL commands,  Implement a simple Pub/Sub mechanism using Redis where notification events are published to channels named by user_id,  Create a basic subscriber function (can be a separate script or background task) that listens to a channel and logs received notifications, and  Add an endpoint to send notifications (POST /notify) that publishes messages to user channels. Include Pydantic models for preference validation, basic authentication using simple token validation, error handling for missing users or Redis failures, pytest tests for CRUD operations on preferences, and logging for published/received messages. Use uvicorn to run the application, provide environment variable configuration for Redis host/port, create a simple Dockerfile, and document the limitations of Redis Pub/Sub (message loss if no subscribers) and when you might need a more robust message queue solution. Include redis-cli commands showing how to manually test your pub/sub implementation."
  ],
  "Python-FastAPI(BASIC),Kafka(BASIC)": [
    "You are building a simple notification service using FastAPI that receives user notifications via HTTP POST requests and publishes them to a Kafka topic called 'notifications'. Your task is to:  Create a FastAPI application with a POST endpoint `/notifications` that accepts a JSON payload containing user_id, message, and notification_type fields using Pydantic models for validation,  Implement a Kafka producer that publishes these notifications to the 'notifications' topic with basic configuration (bootstrap.servers, key and value serializers),  Create a separate consumer script that reads from the 'notifications' topic and prints messages to console with proper offset management using auto.offset.reset='earliest',  Add basic error handling for failed Kafka publishes and return appropriate HTTP status codes, and  Use environment variables to store Kafka broker addresses and configure CORS for the API. Provide the FastAPI service code, producer/consumer implementations, and a simple docker-compose.yml to run Kafka locally.",
    "Your team needs a basic order tracking system where FastAPI receives order updates and stores them in Kafka for downstream processing. The system should handle GET and POST operations. Your task is to:  Create a FastAPI application with two endpoints: POST `/orders` to create new orders (with fields: order_id, customer_name, items, total_amount) and GET `/orders/{order_id}` to retrieve order status,  Implement a Kafka producer that publishes order creation events to an 'orders' topic with order_id as the message key to maintain ordering per order,  Set up basic producer configuration including acks=1, retries=3, and enable.idempotence=true,  Create a consumer that processes orders from the topic and stores them in an in-memory dictionary (simulating a database) with proper group.id configuration,  Add basic logging using Python's logging module to track message publishing and consumption. Include Pydantic models for request validation, basic async endpoints, and explain your choice of partition key.",
    "You are developing a simple event streaming API using FastAPI and Kafka for a monitoring system that collects server metrics. Your task is to:  Create a FastAPI service with a POST endpoint `/metrics` that accepts server metrics (server_id, cpu_usage, memory_usage, timestamp) validated through Pydantic models,  Configure a Kafka producer with basic settings including batch.size, linger.ms=10, and compression.type='gzip' to optimize message sending,  Implement synchronous message sending with callback functions to handle success and error cases, logging the results,  Create a Kafka consumer with session.timeout.ms and max.poll.interval.ms configured appropriately to consume from a 'server-metrics' topic,  Write basic pytest unit tests for the FastAPI endpoint using TestClient, mocking the Kafka producer. Provide the complete service code, Kafka configurations, test cases, and a README with instructions to run the application using uvicorn.",
    "You need to build a basic user registration system where FastAPI handles user signups and publishes events to Kafka for email notifications and analytics. Your task is to:  Create a FastAPI application with POST `/register` endpoint that accepts user registration data (username, email, password) with Pydantic validation,  Implement token-based authentication using FastAPI's HTTPBearer for a protected GET `/profile` endpoint,  Set up a Kafka producer that publishes user registration events to a 'user-registrations' topic with JSON serialization,  Configure the topic with replication-factor=1 and partitions=3 using kafka-topics.sh commands (provide the commands in documentation),  Create a consumer group with two consumers that process registration events, demonstrating consumer group rebalancing by starting/stopping consumers, and add basic CORSMiddleware configuration. Include environment variable management for sensitive data, Docker containerization with a Dockerfile, and explain the difference between at-most-once and at-least-once delivery semantics in your implementation.",
    "Your company needs a simple logging aggregation service where multiple FastAPI microservices send logs to Kafka for centralized processing. Your task is to:  Create a FastAPI application with POST `/logs` endpoint that accepts log entries (service_name, log_level, message, timestamp) with appropriate Pydantic field validators,  Implement a Kafka producer with asynchronous send using producer.send() with futures, handling exceptions appropriately,  Set up a consumer that reads from 'application-logs' topic with enable.auto.commit=false and manual offset commits after processing every 10 messages,  Create a GET `/logs/health` endpoint that checks Kafka broker connectivity and returns broker metadata using AdminClient,  Add simple custom middleware to log all incoming HTTP requests with correlation IDs and write basic integration tests that verify messages are published to Kafka using a test Kafka container. Provide the complete FastAPI service, consumer implementation with proper graceful shutdown handling, docker-compose.yml with Kafka and Zookeeper services, and explain when to use auto commit vs manual commit for offsets."
  ],
  "NodeJs (BASIC), MongoDB (BASIC)": [
    "A product inventory API endpoint /api/products/:category is loading very slowly because it retrieves all product fields from MongoDB even though the frontend only displays name, price, and image. The Node.js route uses Mongoose without any field selection, and it's fetching embedded product reviews (arrays with 100+ reviews per product) that aren't needed for the list view. Additionally, the application creates a new MongoDB connection for every request instead of reusing connections. Optimize by: using Mongoose's select() method to retrieve only required fields, restructuring the MongoDB schema to separate heavy review data into a referenced collection, configuring proper Mongoose connection pooling in the Node.js app.js file, and adding basic response caching using a simple JavaScript object with timestamps (or Redis if available). Show before/after query execution times using console.time() and explain()."
  ],
  "Java (BASIC), Docker (BASIC)": [
    "A Java application's Docker build takes 5 minutes every time due to poor layer caching, the image is 380MB, and the container occasionally crashes with OutOfMemoryError. You're given a simple Java application with a Main.java file. Your tasks:  Create a .dockerignore file to exclude target/, .git/, .idea/, and *.log files,  Write an optimized Dockerfile that: copies pom.xml first and runs 'mvn dependency:go-offline', then copies src/ and runs 'mvn package', and uses openjdk:11-jre-slim instead of openjdk:11, Add -Xmx256m -Xms128m JVM flags in the CMD instruction, (In the Java code, fix one line in a loop where objects are being added to an ArrayList but never cleared (add list.clear() after processing). Demonstrate: image size reduced to under 200MB, rebuild time under 30 seconds when only Java code changes, and container running without memory errors."
  ],
  "Java - Multithread Programming(basic),Java - Distributed Systems Concurrency(basic)": [
    "You are working on a simple file processing application where multiple files need to be read and their word counts calculated. Currently, the application processes files one by one in the main thread, taking 5 seconds per file. With 10 files to process, the total time is 50 seconds. Your task is to: 1) Create a separate thread for each file using either Thread class or Runnable interface to process files concurrently, 2) Use proper thread naming (e.g., 'FileProcessor-1', 'FileProcessor-2') to identify each thread, 3) Use Thread.join() in the main thread to wait for all processing threads to complete before printing the total word count, and 4) Add try-catch blocks inside each thread's run() method to handle potential IOExceptions so one failing file doesn't crash other threads. Demonstrate that processing time is significantly reduced through concurrent execution.",
    "A simple banking application has a bug where two threads can simultaneously withdraw money from the same account, causing the balance to become incorrect. For example, if an account has $100 and two threads each try to withdraw $60, sometimes both withdrawals succeed, leaving a balance of -$20. Your task is to: 1) Identify the race condition in the provided withdraw() method that checks balance and updates it in separate non-atomic steps, 2) Fix the race condition by adding the synchronized keyword to the withdraw() method to ensure only one thread can execute it at a time, 3) Write a simple test using 2-3 threads that attempt concurrent withdrawals to demonstrate the bug is fixed, 4) Add proper validation to prevent negative balances and return a boolean indicating success/failure. Explain in comments why synchronization was necessary and what problem it solved.",
    "You are building a basic message queue system where producer threads add messages to a shared queue and a consumer thread processes them. The current implementation uses a simple ArrayList which causes ConcurrentModificationException when producers add messages while the consumer is iterating. Additionally, the consumer thread runs in a busy loop checking for messages, wasting CPU. Your task is to: 1) Replace ArrayList with a thread-safe collection like Vector or a synchronized wrapper around ArrayList, 2) Implement proper producer-consumer coordination using wait() and notify() - the consumer should wait() when the queue is empty, and producers should notify() after adding messages, 3) Ensure all wait/notify calls are inside synchronized blocks on the shared queue object, and 4) Add a boolean flag mechanism to safely stop both producer and consumer threads (not using deprecated stop()). Demonstrate that messages are processed correctly without exceptions or busy-waiting.",
    "A web scraping application currently uses a single thread to fetch data from 20 different URLs sequentially, taking about 2 seconds per URL (40 seconds total). Your task is to optimize this using basic thread pooling: 1) Refactor the code to use ExecutorService with a fixed thread pool of 5 threads instead of creating threads manually, 2) Submit each URL fetching task to the thread pool using submit() or execute(), 3) Use the shutdown() method to stop accepting new tasks and awaitTermination() to wait for all tasks to complete before exiting, and 4) Add basic exception handling so if one URL fetch fails with an exception, the other tasks continue running. Compare the execution time before and after optimization. You should achieve roughly 4x speedup by processing 5 URLs concurrently.",
    "A simple distributed logging system has multiple application threads writing log messages to a shared log file. The current implementation has two problems: 1) Log messages from different threads are getting interleaved character-by-character making logs unreadable (e.g., 'UseThrr loegaid nA' instead of 'User login' and 'Thread A'), and 2) Occasionally the application hangs because two threads are waiting for each other (a basic deadlock scenario where Thread A locks Resource 1 and waits for Resource 2, while Thread B locks Resource 2 and waits for Resource 1). Your task is to: Fix the interleaved messages by synchronizing the log writing method so each complete message is written atomically, Identify and fix the deadlock by ensuring both threads acquire locks in the same order (Resource 1 first, then Resource 2), Add thread names and timestamps to each log entry using Thread.currentThread().getName() to help with debugging, and Use Thread.sleep() to simulate processing time and make the concurrency issues more visible during testing. Demonstrate both issues are resolved using a simple test with 3-4 threads writing logs concurrently."
  ],
  "Java - Distributed Systems Concurrency(basic)": [
    "You are building a simple distributed task assignment system where a coordinator service distributes tasks to multiple worker nodes via REST API. Currently, the coordinator uses a single thread to send tasks sequentially to 5 worker nodes, taking 2 seconds per REST call (10 seconds total). Your task is to: 1) Create a thread for each worker node using Thread or Runnable to send tasks concurrently via HTTP POST requests, 2) Use Thread.join() to wait for all worker threads to complete before the coordinator proceeds, 3) Handle exceptions (like connection timeouts) inside each thread's run() method so one failing worker doesn't crash the entire coordinator, and 4) Add proper thread naming (e.g., 'Worker-Node-1') and log which worker received which task. Demonstrate that the total time is reduced to approximately 2 seconds through concurrent task distribution.",
    "A distributed counter service allows multiple client threads to increment a shared counter via a REST endpoint. The current implementation has a race condition: the service reads the current count from a file, increments it, and writes it back - but multiple threads can read the same value before any writes occur, causing lost updates. For example, if 10 clients each increment the counter once, the final count might be 3 instead of 10. Your task is to: 1) Identify the race condition in the read-increment-write sequence, 2) Fix it by adding synchronized to the increment method to ensure atomic read-modify-write operations, 3) Replace the file-based counter with a simple thread-safe in-memory counter using a thread-safe collection or synchronized access, and 4) Write a test using 5-10 threads simulating concurrent clients to verify the counter reaches the correct final value. Explain why synchronization was necessary in this distributed scenario.",
    "You are implementing a basic message broker where producer services send messages to a central queue and consumer services retrieve them. The current ArrayList-based queue throws ConcurrentModificationException when multiple producers add messages simultaneously, and consumers waste CPU in busy loops checking for new messages. Your task is to: 1) Replace ArrayList with CopyOnWriteArrayList or a synchronized collection wrapper to handle concurrent producers, 2) Implement wait() and notify() for efficient consumer waiting - consumers should wait() when the queue is empty and producers should notify() after adding messages, 3) Ensure proper synchronization blocks around all wait/notify calls, and 4) Add a graceful shutdown mechanism using a boolean flag that allows the broker to stop accepting new messages and process remaining ones. Test with 2 producer threads and 2 consumer threads to demonstrate correct message delivery without exceptions.",
    "A distributed logging aggregator collects logs from multiple microservices. Currently, each microservice uses a single-threaded HTTP client to send log batches to the aggregator sequentially, causing delays. You need to optimize this using thread pooling: 1) Refactor the log sender to use ExecutorService with a fixed thread pool of 3 threads instead of sending logs one by one, 2) Submit each log batch as a Callable task that returns a success/failure status, 3) Use Future.get() to retrieve results and count how many batches were successfully sent, and 4) Implement proper thread pool shutdown using shutdown() and awaitTermination() to ensure all pending logs are sent before the application exits. Handle exceptions for failed HTTP requests gracefully. Demonstrate improved throughput by sending 15 log batches and measuring time reduction.",
    "A simple distributed configuration service has multiple application nodes reading and updating shared configuration values stored in a central HashMap. The system has two critical bugs: 1) When Node A updates a config value while Node B is iterating through all configs, it throws ConcurrentModificationException, and 2) Deadlock occurs when Node A locks Config-1 then tries to lock Config-2, while Node B locks Config-2 then tries to lock Config-1. Your task is to: Replace HashMap with ConcurrentHashMap to allow safe concurrent reads and updates, Fix the deadlock by ensuring all nodes acquire locks in the same consistent order (alphabetical by config key), Add thread identification to log entries using Thread.currentThread().getName() to help trace which node is doing what, and Use Thread.sleep() to simulate network delays and make the concurrency issues reproducible. "
  ],
  "Java(basic),asynchronous(basic)": [
    "A customer notification system sends SMS alerts synchronously whenever an order status changes, causing the order update API to take 8 seconds to respond while waiting for the SMS gateway. Implement asynchronous notification sending using ExecutorService. Create a NotificationTask implementing Runnable that sends SMS in the background. The order update method should submit the task and return immediately. Use a simple counter or List to track how many notifications are pending vs completed. Add basic exception handling inside the Runnable to catch SMS sending failures and log them without affecting the order update flow. Demonstrate that order updates now complete in under 1 second while notifications process asynchronously.",
    "A blog application generates article preview images synchronously when authors publish posts, blocking the publish action for 15 seconds. Refactor to use asynchronous image generation: implement a Callable<String> that generates the preview image and returns the image URL. Use ExecutorService.submit() to execute the task and store the returned Future in a Map with article ID as key. The publish endpoint should return success immediately with a 'preview generating' status. Create a separate status check method that uses future.isDone() to check if image generation completed, and future.get(1, TimeUnit.SECONDS) with timeout to retrieve the URL. Handle TimeoutException, ExecutionException for failed image generation, and show how to cancel slow-running tasks using future.cancel().",
    "An employee attendance system sends daily summary emails to managers at end of day. Currently, the scheduled job runs synchronously, sending 200+ emails one by one taking 45 minutes and delaying other scheduled tasks. Implement asynchronous email sending using ExecutorService with a fixed thread pool of 5 threads. Create an EmailTask implementing Callable<Boolean> that sends one email and returns success/failure status. Submit all 200 email tasks to the executor and collect the Future objects in a List. Implement a simple monitoring loop that checks how many emails completed using future.isDone() and counts successes vs failures by calling future.get(). Add proper exception handling for email delivery failures. Demonstrate that total execution time reduces to under 10 minutes with parallel processing.",
    "A student exam portal downloads exam papers from a document service when students click 'Start Exam'. The download currently blocks synchronously for 5-7 seconds, causing students anxiety. Implement pre-fetching using asynchronous pattern: when a student logs in, immediately submit a background task using ExecutorService to download their exam paper. Use Callable<byte[]> to return the downloaded content. Store the Future in a session map. When student clicks 'Start Exam', check if future.isDone() - if complete, call future.get() to retrieve cached content instantly; if still downloading, show a brief loading message and wait with future.get(3, TimeUnit.SECONDS). Handle scenarios where download fails using ExecutionException and provide appropriate error message. Show timing comparison between synchronous download (7 seconds) vs pre-fetched async approach (instant).",
    "A product inventory system fetches stock levels from multiple warehouse APIs to display total available quantity. Currently it calls 5 warehouse APIs sequentially taking 10 seconds total (2 seconds each). Implement parallel async fetching: create a StockCheckTask implementing Callable<Integer> that calls one warehouse API and returns stock count. Use ExecutorService to submit 5 tasks simultaneously and collect Future<Integer> objects in a List. Implement aggregation logic that iterates through futures, calls future.get() on each, and sums the results. Add timeout handling using future.get(3, TimeUnit.SECONDS) to skip warehouses that respond slowly. Implement proper exception handling for network failures on individual warehouse calls without failing the entire operation. Demonstrate reduction in total time from 10 seconds to approximately 2-3 seconds with parallel execution."
  ],
  "Golang (BASIC)": [
    "Build a concurrent rate-limited API client from scratch. Create a program that: 1) Define an APIRequest struct with ID int, Endpoint string, Timestamp time.Time, Response string, Duration time.Duration, 2) You need to make 10 API requests but limited to 5 concurrent requests at any time (rate limiting), 3) Implement using a semaphore pattern: create a buffered channel with capacity 5 that acts as a token bucket, 4) Generate 10 API requests to random endpoints (/users, /products, /orders, /analytics), 5) For each request, launch a goroutine that: first acquires a token from semaphore channel (receive from it), makes the API call (simulate with time.Sleep 500ms-1500ms), releases token back to semaphore (send to it), sends result to results channel, 6) Main goroutine sends all requests to a requests channel, 7) Create request processor goroutines that pull from requests channel and execute with rate limiting, 8) Use sync.WaitGroup to track all requests 9) Create a monitor goroutine using select that prints active request count every second, 10) Implement timeout: if any request takes longer than 2 seconds, cancel it and mark as timeout (use select with time.After)."
  ],
  "Python-FastAPI(basic),Redis(basic)": [
    "You are building a simple blog API. Create a GET endpoint that fetches a blog post by ID from a database. To improve performance, implement basic caching: before querying the database, check if the post exists in Redis (using post_id as key). If found, return it from cache. If not, fetch from database, store it in Redis with a 300-second TTL, then return it. The Redis client and database session are already configured and available.",
    "Build a simple visitor counter for your API homepage. Create a GET endpoint for the homepage that increments a counter in Redis each time it's called (use INCR command on a key called 'visitor_count'). The endpoint should return a JSON response with the current visitor count. Also create a second GET endpoint to reset the counter back to zero. Handle the case where Redis is not available and return an appropriate error message.",
    "Implement a basic email verification system. Create a POST endpoint that accepts an email address, generates a random 6-digit verification code, and stores it in Redis with the email as the key and a 10-minute expiration. Create a second POST endpoint that accepts email and code, checks if they match what's stored in Redis, and returns success or failure. Make sure to delete the code from Redis after successful verification to prevent reuse.",
    "You need to track recently viewed products for each user. Create a POST endpoint that accepts user_id and product_id, then adds the product_id to a Redis list for that user (key format: 'user:{user_id}:recent'). Limit the list to the 5 most recent products using LTRIM. Create a GET endpoint that retrieves and returns the list of recently viewed products for a given user_id. Set a 24-hour expiration on the list whenever it's updated.",
    "Build a simple session management system. Create a POST /login endpoint that accepts username and password (validation already provided), generates a random session token, stores it in Redis with key 'session:{token}' containing the username, with 30-minute expiration. Create a GET /profile endpoint that requires a session token in headers, validates it exists in Redis, and returns user information. Create a POST /logout endpoint that deletes the session token from Redis."
  ],
  "Java (BASIC), Java - Spring Boot (BASIC)": [
    "You are working on a Spring Boot REST API for a product catalog service. The application has a ProductService class that currently uses field injection (@Autowired on fields) for its dependencies: ProductRepository, PriceCalculator, and InventoryValidator. Your task is to refactor the ProductService to use constructor-based dependency injection following Spring best practices. Additionally, the PriceCalculator is currently a concrete class, but you need to make it interface-based to support different pricing strategies in the future. Create a PriceCalculator interface with a calculatePrice method, implement a StandardPriceCalculator, and configure it as a @Component. Ensure the ProductService uses constructor injection with the interface type. Write a unit test using JUnit 5 and Mockito to test the ProductService.getProductWithPrice method by mocking the ProductRepository and PriceCalculator dependencies, verifying that the price calculation logic is called correctly."
  ],
  "Apache Camel (BASIC)": [
    "You are working on a Customer Sync service that uses a Camel timer route to periodically synchronize customer data every 60 seconds. The route is defined as 'from(\"timer:syncCustomers?period=60000\").to(\"jdbc:selectNewCustomers\").split(body()).to(\"http://crm-service/customers\")' which queries new customer records from a database using JDBC and sends each customer record to an external CRM service via HTTP POST. The infrastructure consists of a camel-customer-sync container running the Camel application and a mock crm-service container that simulates real-world flakiness by randomly returning HTTP 500 errors or connection timeouts. Currently, when the CRM service fails for any customer record, the entire route crashes with an unhandled exception visible in the logs, causing the sync job to abort and preventing subsequent customers from being processed or future timer triggers from executing properly. The existing route has no error handling configuration—no errorHandler, no onException blocks, and no redelivery policy defined. Your task is to implement robust error handling by adding either a deadLetterChannel errorHandler (such as errorHandler(deadLetterChannel(\"log:dlq\"))) or onException(Exception.class) configuration with redelivery settings that retry each failed HTTP call up to 3 times with a 1-second delay between attempts, ensure that after exhausting retries the route logs detailed error information (customer ID, error message) and continues processing the next customer record without crashing, and verify through logs that the timer continues triggering every 60 seconds, retries are visible in the logs, and the route maintains resilience even when multiple customer records fail to sync with the CRM service."
  ],
  "Python - Numpy (BASIC), Python - Pandas (BASIC)": [
    "You are given a CSV file named 'customer_transactions.csv' containing columns: customer_id, transaction_date, amount, and status. Some rows have missing values in the 'amount' column. Your task is to: (1) Load the CSV file into a Pandas DataFrame, (2) Fill all missing values in the 'amount' column with 0, (3) Filter the DataFrame to show only transactions where status is 'completed', (4) Calculate and print the total sum of amounts for these completed transactions. Provide the complete Python code and the final sum value.",
    "You have a NumPy array representing daily account balances for 10 customers over 5 days (shape: 10×5). Create this array with random integers between 1000 and 5000 using np.random.randint(). Your tasks: (1) Calculate the mean balance for each customer (across all 5 days), (2) Identify which customer has the highest average balance, (3) Create a boolean mask to find all balance entries greater than 3000, (4) Print the customer index with the highest average and the count of balances exceeding 3000.",
    "You are provided with an Excel file 'employee_data.xlsx' containing columns: employee_id, name, department, and salary. The 'salary' column is stored as text (object type) with currency symbols (e.g., '$45,000'). Your task is to: (1) Read the Excel file into a DataFrame, (2) Clean the 'salary' column by removing '$' and ',' characters using .str methods, (3) Convert the 'salary' column to numeric type, (4) Group by 'department' and calculate the mean salary for each department, (5) Display the department with the highest average salary.",
    "Given a Pandas DataFrame with columns 'product_id', 'units_sold', and 'price_per_unit', write code to: (1) Create a new column 'total_revenue' by multiplying 'units_sold' and 'price_per_unit', (2) Sort the DataFrame by 'total_revenue' in descending order, (3) Select the top 5 products by revenue using .head(), (4) Calculate the percentage contribution of each top-5 product to the overall total revenue. The DataFrame contains 50 rows. Print the top 5 products with their revenue percentages.",
    "You have two NumPy arrays: 'actual_sales' and 'forecasted_sales', each containing 20 daily sales figures. Your tasks: (1) Calculate the absolute difference between actual and forecasted sales for each day using NumPy operations, (2) Find the day (index) with the maximum absolute error, (3) Calculate the Mean Absolute Error (MAE) across all 20 days, (4) Create a boolean array identifying days where actual sales exceeded forecasted sales by more than 10%, (5) Print the MAE value, the day with maximum error, and the count of days meeting the 10% threshold."
  ],
  "Retrieval_Augmented_Generation (BASIC)": [
    "You are given an existing RAG system that uses a Dockerized Chroma vector database for document retrieval. The system is currently returning irrelevant documents for user queries because the embedding model was recently changed from 'sentence-transformers/all-MiniLM-L6-v2' to 'sentence-transformers/all-mpnet-base-v2' but the existing documents in the vector store were never re-embedded with the new model. Your task is to: 1) Identify the embedding model mismatch issue in the codebase, 2) Implement a script that re-embeds all existing documents using the new model and updates the Chroma collection, 3) Verify that the Docker container for Chroma is running correctly and the vector DB is accessible, 4) Test the fix with 2-3 sample queries to confirm retrieval relevance has improved. The vector database must remain deployed through Docker—do not attempt to run Chroma as a standalone host service. You have 20 minutes to complete this task.",
    "An existing RAG system using Dockerized Pinecone (via local Docker emulation for testing) is returning duplicate document chunks in retrieval results because the chunking logic has overlapping windows but no deduplication step. When users query 'What is machine learning?', they receive the same paragraph 3-4 times with slightly different surrounding text. Your task is to: 1) Analyze the text chunking code to understand how overlap is being applied (chunk_size=500, overlap=100), 2) Implement a post-retrieval deduplication function that identifies and removes near-duplicate chunks based on cosine similarity threshold (>0.95) or exact text matching, 3) Integrate this deduplication step into the retrieval pipeline without breaking the Docker container setup, 4) Test with sample queries to verify duplicates are eliminated while maintaining answer quality. The vector database must remain deployed through Docker. You have 20 minutes to complete this task.",
    "You are improving an existing RAG system that uses a Dockerized Elasticsearch with k-NN plugin for vector search. The current implementation retrieves top-k=3 documents but often misses relevant context because the value is too low for complex queries. Additionally, the prompt template does not include citation markers, making it difficult to trace which retrieved chunks contributed to the final answer. Your task is to: 1) Locate the retrieval configuration and increase top-k to 7 documents, 2) Modify the prompt template to include citation markers like [Source 1], [Source 2] that reference the retrieved document chunks, 3) Update the context builder to format retrieved chunks with their source identifiers, 4) Ensure the Dockerized Elasticsearch container remains operational and properly configured, 5) Test with 2-3 queries to verify that answers now include traceable citations and improved context coverage. The vector database must be deployed strictly through Docker—do not run Elasticsearch as a standalone host service. You have 20 minutes to complete this task."
  ],
  "ReactJs - Optimization (BASIC), ReactJs (BASIC)": [
    "**Current Implementation:** A multi-tab analytics view eagerly preloads data for all tabs (5+ tabs × 200+ calls per tab = 1,000+ total calls) on initial page load, even though users typically view only one tab. Additionally, switching between tabs triggers unnecessary rerenders of large data lists (thousands of rows), causing noticeable lag and wasted API quota.\n\n**Your Task:** Optimize the loading strategy and render performance without rebuilding the entire analytics view. Focus specifically on:\n- Implementing lazy loading so only the active tab's data is fetched initially\n- Staying within rate limits when loading tab data\n- Preventing unnecessary rerenders when switching tabs\n- Implementing efficient list rendering (virtualization) for large datasets\n- Caching previously loaded tab data to avoid redundant requests\n\n**Success Criteria:** Only necessary data is fetched (respecting rate limits), tab switches feel instant without full rerenders, and the overall page load time is significantly reduced."
  ]
}