{
    "organization": {
        "organization_id": "bfbd7da3-a43b-47dc-b828-146733b5c81e",
        "organization_name": "Utkrusht",
        "organization_background": "Utkrusht is a proof-of-skills marketplace that helps agile teams find talent with strong fundamental concepts with within days. We help aspiring professionals improve their profile with continuous improvement in their skills, documenting their journey and helping them fulfill their potential. We primarily build, conduct, proctor and disseminate proof-of-skill assessments in Technical domains like AI, ML, Fullstack development, High scale distributed systems, DevOps etc but do help non-tech roles like Sales, HR, Marketing etc" 
    },
    "role_context": "A software engineer with 3–5 years of experience in Java and Kafka is expected to take ownership of end-to-end feature delivery — from design discussions to deployment in production. They should be comfortable translating high-level architecture into well-structured, maintainable code and ensuring that components are scalable and resilient. At this stage, the engineer is expected to proactively identify potential bottlenecks, recommend design improvements, and apply best practices in concurrency, distributed messaging, and system integration. They collaborate effectively with product managers, QA, and DevOps teams, while also providing guidance to junior engineers. In addition, they contribute to production readiness by setting up proper monitoring, logging, and alerting for Java/Kafka systems, and they actively participate in incident resolution and post-mortems.",
    "yoe": "3-5",
    "questions_prompt": "Please ensure the questions you ask cover Advanced Concurrency, Asynchronous Patterns, and Performance Optimization in the context of Java and Kafka:\n\n- **Advanced Asynchronous Programming Proficiency**: The candidate should demonstrate deep understanding of Java's asynchronous utilities (CompletableFuture, Executor frameworks, ForkJoinPool, reactive streams) and Kafka's non-blocking producer/consumer patterns. They should be able to design and compose complex async flows, ensure thread safety at scale, handle error propagation across async boundaries, and apply structured concurrency principles. Experience with reactive frameworks (e.g., Project Reactor, RxJava, or Spring WebFlux) is a plus.\n\n- **Designing and Orchestrating Distributed Workflows**: The candidate should be capable of designing scalable and fault-tolerant background workflows using Kafka. This includes managing consumer groups, partitioning strategies, exactly-once semantics, and handling retries and dead-letter topics. They should be able to reason about ordering guarantees, idempotency, and consistency trade-offs when integrating Kafka consumers into larger distributed systems.\n\n- **Performance Tuning and Scalability**: They should be able to identify, measure, and optimize performance bottlenecks in Java/Kafka systems. This includes tuning Kafka configurations (linger.ms, batch.size, fetch.min.bytes), understanding backpressure handling, applying connection pooling strategies, and optimizing serialization/deserialization (Avro, Protobuf, JSON). They should also demonstrate experience with profiling tools (e.g., JFR, VisualVM) and monitoring Kafka/Java applications with metrics (JMX, Prometheus, Grafana) to make data-driven optimizations.\n\nThe goal is to evaluate how the candidate applies advanced async and concurrent patterns in Java and Kafka, designs resilient distributed processing systems, and proactively optimizes performance for production-grade applications."
}
