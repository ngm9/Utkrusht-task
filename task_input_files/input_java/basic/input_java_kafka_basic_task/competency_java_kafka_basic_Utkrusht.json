[
    {
        "competency_id": "c9bd828d-58c2-4377-9ea7-be5044ecc284",
        "created_at": "2025-07-29T03:14:19.087072+00:00",
        "proficiency": "BASIC",
        "organization_id": "bfbd7da3-a43b-47dc-b828-146733b5c81e",
        "name": "Java",
        "scope": "A person with BASIC proficiency level in Java as a competency should be able to understand the Java execution model (JDK, JRE, JVM) and write maintainable code using proper packages and naming conventions. They possess foundational proficiency in Java syntax, including control flow, error handling, and basic class structures. Their knowledge of OOP principles (Encapsulation, Inheritance, Polymorphism, Abstraction) allows them to create coherent classes with appropriate access modifiers. They are comfortable employing Java’s core collections (List, Set, Map), grasping performance impacts of ArrayList vs LinkedList and HashMap vs TreeMap. They handle exceptions using try-catch-finally and appreciate the difference between checked and unchecked exceptions. Their concurrency awareness extends to creating and running simple threads, with a limited understanding of race conditions and synchronization. They can effectively use IDEs (e.g., IntelliJ, Eclipse), basic build tools (Maven, Gradle), and version control (Git) for daily tasks and collaboration. They have exposure to simple frameworks or libraries like JDBC for database connectivity, JUnit for testing, and minimal Spring Boot configurations. They follow introductory best practices such as organizing code, avoiding duplication, and adhering to naming standards, with an initial grasp of SOLID principles. They can debug code using IDE breakpoints, write straightforward test cases, and refactor small code snippets to address performance or readability concerns. They have participated in at least one small Java project, handled feature development, bug fixes, and engaged in code reviews. Their approach to software development involves basic Agile or similar methodologies, ensuring they can communicate effectively within a team."
    },
    {
        "competency_id": "50f5e386-08e5-402b-a515-98c646ca4245",
        "created_at": "2025-07-29T03:14:19.087072+00:00",
        "proficiency": "BASIC",
        "organization_id": "bfbd7da3-a43b-47dc-b828-146733b5c81e",
        "name": "Kafka",
        "scope": "A person with BASIC proficiency level in Kafka as a competency should be able to describe the full log-based architecture—topics, partitions, offsets, leader–follower replication, ISR, high-water-mark, ordering guarantees, retention and compaction policies—plus delivery semantics (at-most/least/exactly-once) and the roles of brokers, ZooKeeper or KRaft controllers, producers and consumers. They can code producers/consumers in official client SDKs (Java, Scala, Kotlin, Python, Go, .NET) using configs such as bootstrap.servers, serializers/Serdes, acks, retries, linger.ms, batch.size, compression.type, idempotence, transactional.id, group.id, enable.auto.commit, auto.offset.reset, session.timeout.ms and max.poll.* while handling synchronous/asynchronous sends, callbacks, graceful shutdown and simple Avro/Protobuf/JSON-Schema Registry integration. They create, alter and delete topics with kafka-topics.sh, kafka-configs.sh, kafka-consumer-groups.sh, kcat/kafkacat, AdminClient or REST, choosing replication-factor, partition-count, cleanup.policy, retention.ms/bytes, min.insync.replicas and understanding unclean.leader.election impacts. They spin up and manage single or small multi-broker clusters via local installs, Docker Compose, containers or managed services like Confluent Cloud, AWS MSK and Azure Event Hubs, interpret broker logs, observe leader distribution, ISR, consumer-group lag and reset offsets when required. They tune basics—segment.bytes, segment.ms, retention, compression, producer batching, num.network/io/handler threads, broker heap (4–8 GB) and page cache awareness—to reach predictable throughput and latency for small-scale loads. They enable PLAINTEXT for dev and configure TLS certificates, SASL/PLAIN or SASL/SCRAM users, truststore/keystore files and ACLs for simple prod isolation. They export JMX metrics from brokers and clients to Prometheus (jmx_exporter) or similar, build dashboards for throughput, latency, lag, under-replicated/offline partitions and request queues, and can triage leader-not-available errors, rebalance storms, disk-full or lag explosions. They use partitioning strategies (key-hash, round-robin, custom) to reason about parallelism and ordering, and understand consumer-group rebalancing phases and cooperative vs eager protocols. They can deploy and configure out-of-the-box Kafka Connect source/sink connectors (file, JDBC, S3, Elastic, etc.) with converters, and know where Kafka Streams, ksqlDB, Flink or Spark Structured Streaming fit without yet mastering them. They embed topic scripts, client configs and monitoring hooks into CI/CD and IaC (Docker Compose, Terraform, Helm), write/run unit tests, review peer code for correctness, and participate in incident calls with first-line Kafka diagnostics. While competent at day-to-day dev/ops for clusters up to a few TB, they are not yet accountable for multi-AZ sizing, cross-DC replication, deep JVM/OS tuning, advanced transactions or complex stream-processing topologies."
    }
]